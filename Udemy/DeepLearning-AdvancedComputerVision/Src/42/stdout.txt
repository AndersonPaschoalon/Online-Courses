TensorFlow version: 2.9.0
2022-09-27 10:30:47.266550: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2022-09-27 10:30:47.266754: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-09-27 10:30:47.274350: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: N933
2022-09-27 10:30:47.274690: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: N933
2022-09-27 10:30:47.275117: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_1 (InputLayer)        [(None, 100, 100, 3)]     0

 block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792

 block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928

 block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0

 block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856

 block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584

 block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0

 block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168

 block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080

 block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080

 block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0

 block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160

 block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808

 block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808

 block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0

 block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808

 block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808

 block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808

 block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0

 flatten (Flatten)           (None, 4608)              0

 dense (Dense)               (None, 8)                 36872

=================================================================
Total params: 14,751,560
Trainable params: 36,872
Non-trainable params: 14,714,688
_________________________________________________________________
-- gen.flow_from_directory
Found 1285 images belonging to 8 classes.
-- test_gen.class_indices: {'Apple Golden 1': 0, 'Avocado': 1, 'Banana': 2, 'Kiwi': 3, 'Lemon': 4, 'Mango': 5, 'Raspberry': 6, 'Strawberry': 7}
min: -94.75322 , max: 151.061
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Found 3827 images belonging to 8 classes.
Found 1285 images belonging to 8 classes.
Epoch 1/5
119/119 [==============================] - 436s 4s/step - loss: 0.9622 - accuracy: 0.9352 - val_loss: 0.1120 - val_accuracy: 0.9836
Epoch 2/5
119/119 [==============================] - 372s 3s/step - loss: 0.0784 - accuracy: 0.9905 - val_loss: 0.1222 - val_accuracy: 0.9875
Epoch 3/5
119/119 [==============================] - 406s 3s/step - loss: 0.0233 - accuracy: 0.9974 - val_loss: 0.0166 - val_accuracy: 0.9977
Epoch 4/5
119/119 [==============================] - 283s 2s/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 1.2708e-04 - val_accuracy: 1.0000
Epoch 5/5
119/119 [==============================] - 350s 3s/step - loss: 0.0268 - accuracy: 0.9974 - val_loss: 0.0119 - val_accuracy: 0.9984
Generating confusion matrix 3827
Found 3827 images belonging to 8 classes.
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 5s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 3s 2s/step
2/2 [==============================] - 3s 2s/step
2/2 [==============================] - 3s 2s/step
2/2 [==============================] - 3s 2s/step
2/2 [==============================] - 3s 2s/step
2/2 [==============================] - 3s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 5s 3s/step
2/2 [==============================] - 5s 2s/step
2/2 [==============================] - 5s 3s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 3s 2s/step
2/2 [==============================] - 4s 2s/step
50
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 5s 2s/step
2/2 [==============================] - 5s 2s/step
2/2 [==============================] - 5s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 1s/step
[[478   0   0   0   2   0   0   0]
 [  0 427   0   0   0   0   0   0]
 [  0   0 490   0   0   0   0   0]
 [  0   0   0 466   0   0   0   0]
 [  0   0   0   0 492   0   0   0]
 [  0   0   0   0   0 490   0   0]
 [  0   0   0   0   0   0 490   0]
 [  0   0   0   0   0   0   0 492]]
Generating confusion matrix 1285
Found 1285 images belonging to 8 classes.
2/2 [==============================] - 5s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 3s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 5s 2s/step
2/2 [==============================] - 3s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 3s 2s/step
2/2 [==============================] - 4s 2s/step
2/2 [==============================] - 5s 3s/step
2/2 [==============================] - 5s 2s/step
2/2 [==============================] - 5s 2s/step
2/2 [==============================] - 5s 2s/step
2/2 [==============================] - 4s 2s/step
1/1 [==============================] - 0s 312ms/step
[[156   0   0   0   4   0   0   0]
 [  0 142   0   0   0   1   0   0]
 [  0   1 165   0   0   0   0   0]
 [  0   0   0 156   0   0   0   0]
 [  0   0   0   0 164   0   0   0]
 [  0   0   0   0   0 166   0   0]
 [  0   0   0   0   0   0 166   0]
 [  0   0   0   0   0   0   0 164]]
Confusion matrix, without normalization
[[478   0   0   0   2   0   0   0]
 [  0 427   0   0   0   0   0   0]
 [  0   0 490   0   0   0   0   0]
 [  0   0   0 466   0   0   0   0]
 [  0   0   0   0 492   0   0   0]
 [  0   0   0   0   0 490   0   0]
 [  0   0   0   0   0   0 490   0]
 [  0   0   0   0   0   0   0 492]]
Confusion matrix, without normalization
[[156   0   0   0   4   0   0   0]
 [  0 142   0   0   0   1   0   0]
 [  0   1 165   0   0   0   0   0]
 [  0   0   0 156   0   0   0   0]
 [  0   0   0   0 164   0   0   0]
 [  0   0   0   0   0 166   0   0]
 [  0   0   0   0   0   0 166   0]
 [  0   0   0   0   0   0   0 164]]